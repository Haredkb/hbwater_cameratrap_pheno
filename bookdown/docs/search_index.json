[["index.html", "A Guide to an Image Processing Pipeline and Classification with Machine Learning Chapter 1 About this book 1.1 Load Packages 1.2 Introduction", " A Guide to an Image Processing Pipeline and Classification with Machine Learning Henry Sun, Biniam Garomsa, Hector Ontiveros 2022-06-23 Chapter 1 About this book This book was authored to serve as a basic guide for using the data pipeline to process raw images using ROI software, VIA image annotation, and a machine learning model. Special thanks to Audrey Thellman and Weston Slaughter for their guidance and mentorship. 1.1 Load Packages library(bookdown) # Knits markdown files into a book library(reticulate) # Allows python code to be ran in an R environment 1.2 Introduction The primary target users of this software are river ecologists looking to extract data from camera traps. Freshwater systems are losing ice rapidly due to rising global temperatures. Currently, studies on river ice ecology are patchy, and more so regarding small-scale rivers. Our teams images are those from the Hubbard Brook Experimental Forest in New Hampshire, United States. Nine camera traps in as many watersheds have collected images daily for three years, from which the Hubbard Brook Ecosystem Study and the U.S. Geological Survey can extract data using our product. Our software can however be viably used for any class of field imagery and classification. "],["rename-raw-images.html", "Chapter 2 Rename Raw Images 2.1 Copying Files", " Chapter 2 Rename Raw Images Renaming images is the first key step in this data processing pipeline. For our study, field camera traps in various watersheds at Hubbard Brook Experimental Forest took one photo each day over a timespan of several years. The original file names were a nondescriptive series of numbers, following this step, they will contain information about the watershed the photo was taken at as well as timeseries image metadata. These steps were designed to process files stored in a shared Google Drive. Before renaming images contained in a local directory, modifications to the script will need to be made; however, the same general principles will still apply. 2.0.1 Mount Google Drive # This will connect to your Google Drive. It will ask you to allow access drive.mount(&#39;/content/drive&#39;, force_remount=True) When using Google Colaboratory, before performing any file operations, you must mount your personal Google Drive. Run the above code to allow access. Afterwards, make sure all file paths used in any functions are for your Google Drive specifically. To find a pathname, click the orange file icon on Google Colab’s sidebar, and then click content to navigate your Google Drive. Right-click and select copy path to copy the pathname. 2.1 Copying Files This preliminary step is used when a backup or copy of the original data is needed. It will copy all files in the source directory not present in the target directory. 2.1.1 Load Packages Before each session, first run the top 3 lines – these lines of code install the Tesseract Optical Character Recognition Engine, which allows us to later use the text_to_string function and read the timestamp from each image. Subsequently, load all required packages/libraries. apt install tesseract-ocr apt install libtesseract-dev pip install pytesseract import numpy as np import pandas as pd import re import os import shutil from google.colab import drive from glob import glob 2.1.2 Copying Files This method uses shutil’s copytree function, which blanket copies all files within a specified directory. To handle issues caused by direct copying of files versus copying of subdirectories, these are copied separate from each other within the code. if missing_files == source_file_list: # Will copy entire source folder into destination when no subfolders/files are shared between the two shutil.copytree(source, destination + &#39;/&#39; + directory_name, ignore = shutil.ignore_patterns(&#39;*.gdoc&#39;, &#39;*.gsheet&#39;, &#39;*.gslides&#39;)) #1 else: for folder in missing_files: # Will copy all missing files/subfolders not present in the destination new_dst = destination + &#39;/&#39; + folder if os.path.isfile(folder) == False: # Copies all subfolders/subdirectories shutil.copytree(source + &#39;/&#39; + folder, new_dst, ignore = shutil.ignore_patterns(&#39;*.gdoc&#39;, &#39;*.gsheet&#39;, &#39;*.gslides&#39;)) #1 missing_files.remove(folder) else: # Copies files not contained within a subdirectory shutil.copy(source + &#39;/&#39; + folder, destination) missing_files.remove(folder) print(&quot;These folders/files were not copied (ignore if list is empty): &quot;) print(missing_files) Copying any Google files, be it Google Docs, Slides, Sheets, Drawings, etc. must be done manually as these files are special and not able to be copied using shutil1. For any additional file extensions to avoid copying, specify them as arguments for shutil.ignore_patterns. 2.1.3 Main Method Finally, to copy the files, simply call copy_files within the main method. This method takes 3 arguments – the file path for the source folder, the file path for the destination folder, and a folder name for the folder created if the source and destination directories share no files. args = (&quot;/content/drive/MyDrive/Duke 2022-2023/Data+/2_Camera Trap photos/Stream Photos/On_Deck&quot;, &quot;/content/drive/MyDrive/Duke 2022-2023/Data+/2_Camera Trap photos/COPY of data for script/On_Deck&quot;, &quot;Newly_uploaded_data&quot;) copy_files(*args) ] ## Renaming Files For more information, see the comments within the script and text blocks in the Jupyter Notebook↩︎ "],["selecting-region-of-interest.html", "Chapter 3 Selecting Region of Interest", " Chapter 3 Selecting Region of Interest This chapter provides an overview about the Python scripts used to create a polygonal region of interest and mask for images contained in folders. "],["classifying-image-attributes-with-via.html", "Chapter 4 Classifying Image Attributes with VIA", " Chapter 4 Classifying Image Attributes with VIA TBA "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
