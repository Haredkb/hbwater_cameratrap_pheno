{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Trap to Random Forests in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tesseract\n",
    "# ! pip install tesseract-ocr # did not work\n",
    "# ! pip install libtesseract-dev #did not work\n",
    "# ! pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:/Users/athellma/OneDrive - University of North Carolina at Chapel Hill/Documents/Duke University/Research/_HBEF/CameraTrapAnalysis/hbwater_cameratrap_pheno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "from datetime import datetime as dt\n",
    "import ast\n",
    "import itertools\n",
    "from PIL import Image\n",
    "#import packages\n",
    "import pytesseract\n",
    "#Set tesseract location\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\" \n",
    "import glob\n",
    "import cv2\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Wrangle the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:19: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:19: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\athellma\\AppData\\Local\\Temp\\ipykernel_41420\\1198062038.py:19: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  temp_pattern = \"\\d\\dF\" # eg 37F3C or 30F-1C\n"
     ]
    }
   ],
   "source": [
    "def extract_temperature(pic_address):\n",
    "    '''\n",
    "    Extract temperature from picture file.\n",
    "\n",
    "    From the middle of each picture file, the time stamp is read as image using cv2. It is then converted to a string.\n",
    "    text which is then checked for format and subsequently returned through temp_format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pic_address : full source address of current picture file.\n",
    "    Returns\n",
    "    -------\n",
    "    temp_format.group(0) : unaltered temperature from bottom of the photo as a string.\n",
    "    '''\n",
    "\n",
    "    img = cv2.imread(pic_address) #read as an image\n",
    "\n",
    "    # check if the timestamp is the correct format\n",
    "    temp_pattern = \"\\d\\dF\" # eg 37F3C or 30F-1C\n",
    "\n",
    "    loop = 5\n",
    "    size_extension=0\n",
    "    x,y,z = np.shape(img)\n",
    "    x = (x//1000)*1000\n",
    "\n",
    "    y = (y//1000)*1000\n",
    "    # print(x,y,z)\n",
    "    while loop>0:\n",
    "        ts = img[2300 - size_extension:, 1400-size_extension:, :] #(change start values manually if sizing conventions change!)\n",
    "        text = pytesseract.image_to_string(ts)\n",
    "        temp_format = re.search(temp_pattern,text)\n",
    "        if temp_format:\n",
    "            # found temperature, return\n",
    "            break\n",
    "        ts_2 = img[2430 - size_extension:, 1565-size_extension:, :] #(change start values manually if sizing conventions change!)\n",
    "        text_2= pytesseract.image_to_string(ts_2)\n",
    "        temp_format = re.search(temp_pattern,text_2)\n",
    "        if temp_format:\n",
    "        # found temperature, return\n",
    "            break\n",
    "        size_extension+=50\n",
    "        loop-=1\n",
    "\n",
    "    if loop ==0:      \n",
    "      # reached end of loop without finding correct timestamp\n",
    "        return np.nan\n",
    "        # return None\n",
    "    \n",
    "    return temp_format.group(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_data(df):\n",
    "    \"\"\"\n",
    "    wrangle via annotated data to produce dataframe of pixel coordinates with their corresponding\n",
    "    RGB values, class and temperature info\n",
    "    \n",
    "    \"\"\"\n",
    "    # extract region attributes to produce class variable\n",
    "    for i in range(df.shape[0]):\n",
    "        try:\n",
    "            json_item = json.loads(df['region_attributes'][i])\n",
    "            keys = list(json_item[\"attribute\"].keys())\n",
    "            df.loc[i,\"class\"] = keys[0]\n",
    "        except:\n",
    "            print(\"Not able to extract region attributes at row {}\".format(i))\n",
    "    \n",
    "    # convert json code to python dictionary\n",
    "    for i in range(df.shape[0]):\n",
    "        dictionary = ast.literal_eval(df.loc[i, \"region_shape_attributes\"])\n",
    "        for k,v in dictionary.items():\n",
    "            df.loc[i,k ] = v\n",
    "        \n",
    "    # change to int type\n",
    "    for col in [\"x\", \"y\", \"width\",\"height\"]:\n",
    "        df[col] = df[col].astype('Int64')\n",
    "        \n",
    "    # dictionary of filename data\n",
    "    filename_data = {\n",
    "        'system': [],\n",
    "        'watershed': [],\n",
    "        'date': [],\n",
    "        'pic_id': [],\n",
    "    }\n",
    "\n",
    "    # loop through filename string to add filename data\n",
    "    for i in range(len(df['filename'])):\n",
    "        # split contents by underscore\n",
    "        file_items = df['filename'][i].split('_')\n",
    "\n",
    "        # add system column for 'hbwtr'\n",
    "        filename_data['system'].append(file_items[1])\n",
    "        # add watershed olumn, 'w1', 'w2', etc.\n",
    "        filename_data['watershed'].append(file_items[2])\n",
    "        # add date column\n",
    "        filename_data['date'].append(\n",
    "                                    # modify integer date to date format, MM/DD/YYYY\n",
    "                                    dt.strptime(file_items[3], '%Y%m%d').strftime('%m/%d/%Y')\n",
    "                                    )\n",
    "        # add picture id number\n",
    "        filename_data['pic_id'].append(file_items[4])\n",
    "\n",
    "    # create columns of this data in dataframe\n",
    "    for variable in filename_data.keys():\n",
    "        df[variable] = filename_data[variable]\n",
    "        \n",
    "\n",
    "    # make list to reorder columns\n",
    "    new_cols = ['filename', 'region_count', 'region_id', 'class', 'name', 'x','y', 'width', 'height',  'system','watershed', 'date', 'pic_id']\n",
    "\n",
    "    df = df[new_cols]\n",
    "    \n",
    "    # create image dictionary and temperature dictionary\n",
    "    image_dict = {}\n",
    "    temp_dict = {}\n",
    "    def my_func(row):\n",
    "        if row[\"filename\"] in image_dict:\n",
    "            return\n",
    "        path =  \"example_data/\"+row[\"filename\"] # sample path to example data folder with all images\n",
    "        # note to Audrey: can you change this to read the images recursively (e.g. find file regardless of path)\n",
    "        img= np.asarray(Image.open(path)) #note to Audrey: read in raw images, not inverted images?\n",
    "        image_dict[row[\"filename\"]] = img\n",
    "        temp_dict[row[\"filename\"]] = extract_temperature(path)\n",
    "    _ = df.apply(lambda c: my_func(c),axis=1)\n",
    "    \n",
    "    \n",
    "    # Assign image pixel values for each row by extracting RGB using x,y coordinates\n",
    "    \n",
    "    # drop na values in x and y column\n",
    "    df = df.dropna(subset= [\"x\",\"y\"])\n",
    "    # save new data points to this list\n",
    "    li = []\n",
    "    # loop over all rows and poopulate pixel coordinates\n",
    "    for ind, row in df.iterrows():\n",
    "        y_range = (row.y, row.y+row.height)\n",
    "        x_range = (row.x, row.x+row.width)\n",
    "        # print(y_range, x_range)\n",
    "        # calculate the coordinates range in the x and y axis\n",
    "        range_list =  [range(row.x, row.x+row.width), range(row.y,row.y+row.height)]\n",
    "        # set product of x_range and y_range\n",
    "        combination_list = list(itertools.product(*range_list))\n",
    "        width, height = 1,1\n",
    "        # append new row entry for every pixel locations within y_range and x_range\n",
    "        for new_x, new_y in combination_list:       \n",
    "            li.append([row[\"filename\"],  new_x, new_y, width, height, row[\"class\"]])\n",
    "      \n",
    "    pixels_df = pd.DataFrame(li, columns=['filename', 'x', 'y', 'width', 'height', 'class'])\n",
    "    # print(pixels_df.head())\n",
    "    \n",
    "    # function to assign pixel RGB values using image dictionary\n",
    "    def assign_pixels(row):\n",
    "        return image_dict[row[\"filename\"]][row.y:row.y+1, row.x:row.x+1].flatten()\n",
    "    pixels_df[\"RGB\"] = pixels_df.apply(lambda row: assign_pixels(row),axis=1)\n",
    "\n",
    "    # create color channels\n",
    "    pixels_df[\"R\"] = pixels_df.apply(lambda row: np.int64(row[\"RGB\"][0]),axis=1)\n",
    "    pixels_df[\"G\"] = pixels_df.apply(lambda row: np.int64(row[\"RGB\"][1]),axis=1)\n",
    "    pixels_df[\"B\"] = pixels_df.apply(lambda row: np.int64(row[\"RGB\"][2]),axis=1)\n",
    "    # create temperature column\n",
    "    pixels_df[\"temperature\"] = pixels_df.apply(lambda row: temp_dict[row[\"filename\"]][:2])\n",
    "    # change date to pandas datetime\n",
    "    pixels_df[\"date\"] = pd.to_datetime(pixels_df[\"date\"])\n",
    "\n",
    "    df = pixels_df[[\"x\",\"y\",\"R\",\"G\",\"B\",\"temperature\", \"class\"]]\n",
    "\n",
    "    # drop all missing values\n",
    "    df = df.fillna(value=np.nan)\n",
    "    df = df.dropna()\n",
    "    # remove duplicate RGB\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring in the CSV data. The data is also available in JSON, which may actually be the most intuitive and efficient structure to unpack from in the long run.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>file_size</th>\n",
       "      <th>file_attributes</th>\n",
       "      <th>region_count</th>\n",
       "      <th>region_id</th>\n",
       "      <th>region_shape_attributes</th>\n",
       "      <th>region_attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invert_Hbwtr_w1_20190101_120000.JPG</td>\n",
       "      <td>166822</td>\n",
       "      <td>{\"attribute\":{}}</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":1220,\"y\":2020,\"width\":102,\"...</td>\n",
       "      <td>{\"attribute\":{\"snow_o\":true}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invert_Hbwtr_w1_20190101_120000.JPG</td>\n",
       "      <td>166822</td>\n",
       "      <td>{\"attribute\":{}}</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":1407,\"y\":1881,\"width\":111,\"...</td>\n",
       "      <td>{\"attribute\":{\"snow_o\":true}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>invert_Hbwtr_w1_20190101_120000.JPG</td>\n",
       "      <td>166822</td>\n",
       "      <td>{\"attribute\":{}}</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":1482,\"y\":2023,\"width\":72,\"h...</td>\n",
       "      <td>{\"attribute\":{\"snow_o\":true}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invert_Hbwtr_w1_20190101_120000.JPG</td>\n",
       "      <td>166822</td>\n",
       "      <td>{\"attribute\":{}}</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":1103,\"y\":1881,\"width\":102,\"...</td>\n",
       "      <td>{\"attribute\":{\"snow_o\":true}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>invert_Hbwtr_w1_20190101_120000.JPG</td>\n",
       "      <td>166822</td>\n",
       "      <td>{\"attribute\":{}}</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":1653,\"y\":1878,\"width\":60,\"h...</td>\n",
       "      <td>{\"attribute\":{\"snow_o\":true}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename  file_size   file_attributes  \\\n",
       "0  invert_Hbwtr_w1_20190101_120000.JPG     166822  {\"attribute\":{}}   \n",
       "1  invert_Hbwtr_w1_20190101_120000.JPG     166822  {\"attribute\":{}}   \n",
       "2  invert_Hbwtr_w1_20190101_120000.JPG     166822  {\"attribute\":{}}   \n",
       "3  invert_Hbwtr_w1_20190101_120000.JPG     166822  {\"attribute\":{}}   \n",
       "4  invert_Hbwtr_w1_20190101_120000.JPG     166822  {\"attribute\":{}}   \n",
       "\n",
       "   region_count  region_id                            region_shape_attributes  \\\n",
       "0            31          0  {\"name\":\"rect\",\"x\":1220,\"y\":2020,\"width\":102,\"...   \n",
       "1            31          1  {\"name\":\"rect\",\"x\":1407,\"y\":1881,\"width\":111,\"...   \n",
       "2            31          2  {\"name\":\"rect\",\"x\":1482,\"y\":2023,\"width\":72,\"h...   \n",
       "3            31          3  {\"name\":\"rect\",\"x\":1103,\"y\":1881,\"width\":102,\"...   \n",
       "4            31          4  {\"name\":\"rect\",\"x\":1653,\"y\":1878,\"width\":60,\"h...   \n",
       "\n",
       "               region_attributes  \n",
       "0  {\"attribute\":{\"snow_o\":true}}  \n",
       "1  {\"attribute\":{\"snow_o\":true}}  \n",
       "2  {\"attribute\":{\"snow_o\":true}}  \n",
       "3  {\"attribute\":{\"snow_o\":true}}  \n",
       "4  {\"attribute\":{\"snow_o\":true}}  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read via annotated image pixels data\n",
    "# we will use three data sets( from watershed 3 and watershed 6)\n",
    "#csv_1 = pd.read_csv('example_data/hbwater_w3_bottom_1_1_20-3_5_20_csv.csv') #this file name was swapped out for wrangle\n",
    "csv_1 = pd.read_csv('data/training_data/input_data/hbwtr_w1_2019_bottom.csv')\n",
    "csv_2 = pd.read_csv(\"data/training_data/input_data/hb2_w6_2019_top_csv.csv\")\n",
    "csv_3 = pd.read_csv(\"data/training_data/input_data/hbwtr_w6_oct2018dec2018_bottom_csv.csv\")\n",
    "csv_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not able to extract region attributes at row 1322\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\athellma\\\\OneDrive - University of North Carolina at Chapel Hill\\\\Documents\\\\Duke University\\\\Research\\\\_HBEF\\\\CameraTrapAnalysis\\\\hbwater_cameratrap_pheno\\\\example_data\\\\invert_Hbwtr_w1_20190101_120000.JPG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# main function\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m csv_1 \u001b[38;5;241m=\u001b[39m \u001b[43mwrangle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m csv_2 \u001b[38;5;241m=\u001b[39m wrangle_data(csv_2)\n\u001b[0;32m      4\u001b[0m csv_3 \u001b[38;5;241m=\u001b[39m wrangle_data(csv_3)\n",
      "Cell \u001b[1;32mIn[7], line 71\u001b[0m, in \u001b[0;36mwrangle_data\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     69\u001b[0m     image_dict[row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m img\n\u001b[0;32m     70\u001b[0m     temp_dict[row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m extract_temperature(path)\n\u001b[1;32m---> 71\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmy_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Assign image pixel values for each row by extracting RGB using x,y coordinates\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# drop na values in x and y column\u001b[39;00m\n\u001b[0;32m     77\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\athellma\\OneDrive - University of North Carolina at Chapel Hill\\Documents\\Duke University\\Research\\_HBEF\\CameraTrapAnalysis\\hbwater_cameratrap_pheno\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\athellma\\OneDrive - University of North Carolina at Chapel Hill\\Documents\\Duke University\\Research\\_HBEF\\CameraTrapAnalysis\\hbwater_cameratrap_pheno\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\athellma\\OneDrive - University of North Carolina at Chapel Hill\\Documents\\Duke University\\Research\\_HBEF\\CameraTrapAnalysis\\hbwater_cameratrap_pheno\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\athellma\\OneDrive - University of North Carolina at Chapel Hill\\Documents\\Duke University\\Research\\_HBEF\\CameraTrapAnalysis\\hbwater_cameratrap_pheno\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[7], line 71\u001b[0m, in \u001b[0;36mwrangle_data.<locals>.<lambda>\u001b[1;34m(c)\u001b[0m\n\u001b[0;32m     69\u001b[0m     image_dict[row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m img\n\u001b[0;32m     70\u001b[0m     temp_dict[row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m extract_temperature(path)\n\u001b[1;32m---> 71\u001b[0m _ \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m c: \u001b[43mmy_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Assign image pixel values for each row by extracting RGB using x,y coordinates\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# drop na values in x and y column\u001b[39;00m\n\u001b[0;32m     77\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[7], line 68\u001b[0m, in \u001b[0;36mwrangle_data.<locals>.my_func\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     67\u001b[0m path \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_data/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mrow[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;66;03m# sample path to example data folder with all images\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m img\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m#note to Audrey: read in raw images, not inverted images?\u001b[39;00m\n\u001b[0;32m     69\u001b[0m image_dict[row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m img\n\u001b[0;32m     70\u001b[0m temp_dict[row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m extract_temperature(path)\n",
      "File \u001b[1;32mc:\\Users\\athellma\\OneDrive - University of North Carolina at Chapel Hill\\Documents\\Duke University\\Research\\_HBEF\\CameraTrapAnalysis\\hbwater_cameratrap_pheno\\.venv\\Lib\\site-packages\\PIL\\Image.py:3431\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3431\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3432\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\athellma\\\\OneDrive - University of North Carolina at Chapel Hill\\\\Documents\\\\Duke University\\\\Research\\\\_HBEF\\\\CameraTrapAnalysis\\\\hbwater_cameratrap_pheno\\\\example_data\\\\invert_Hbwtr_w1_20190101_120000.JPG'"
     ]
    }
   ],
   "source": [
    "# main function\n",
    "csv_1 = wrangle_data(csv_1)\n",
    "csv_2 = wrangle_data(csv_2)\n",
    "csv_3 = wrangle_data(csv_3)\n",
    "# wrangle and save dataset\n",
    "csv_1.to_csv(\"data/training_data/derived/pixels_df_1.csv\", index=False)\n",
    "csv_2.to_csv(\"data/training_data/derived/pixels_df_2.csv\", index=False)\n",
    "csv_3.to_csv(\"data/training_data/derived/pixels_df_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "76d7c06053c3456e5600312cec90888656fc0ed30c03d8425b9dac6e4fc8e014"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
